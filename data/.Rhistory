lda.pred$class
# Cross tabulating the result
table(correct = correct_classes, predicted = lda.pred$class)
library(caret); library(lattice)
confusionMatrix(correct, predict(lda.pred$class))
# Predicting classes with the test data
lda.pred <- predict(lda.fit, newdata = test)
lda.pred$class
# Cross tabulating the result
table(correct = correct_classes, predicted = lda.pred$class)
library(caret); library(lattice)
confusionMatrix(correct_classes, predict(lda.pred$class))
# Predicting classes with the test data
lda.pred <- predict(lda.fit, newdata = test)
lda.pred$class
# Cross tabulating the result
table1 <- table(correct = correct_classes, predicted = lda.pred$class)
table1
library(caret); library(lattice)
confusionMatrix(table1)
# Predicting classes with the test data
lda.pred <- predict(lda.fit, newdata = test)
lda.pred$class
# Cross tabulating the result
table1 <- table(correct = correct_classes, predicted = lda.pred$class)
table1
library(caret); library(lattice)
confusionMatrix("table1")
# Predicting classes with the test data
lda.pred <- predict(lda.fit, newdata = test)
lda.pred$class
# Cross tabulating the result
table1 <- table(correct = correct_classes, predicted = lda.pred$class)
table1
library(caret); library(lattice)
confusionMatrix(lda.pred, correct_classes)
# Predicting classes with the test data
lda.pred <- predict(lda.fit, newdata = test)
lda.pred$class
# Cross tabulating the result
table1 <- table(correct = correct_classes, predicted = lda.pred$class)
table1
library(caret); library(lattice)
confusionMatrix(correct_classes, lda.pred)
install.packages("mlbench")
# Predicting classes with the test data
lda.pred <- predict(lda.fit, newdata = test)
lda.pred$class
# Cross tabulating the result
table1 <- table(correct = correct_classes, predicted = lda.pred$class)
table1
library(caret); library(lattice); library(mlbench)
confusionMatrix(correct_classes, lda.pred)
# Predicting classes with the test data
lda.pred <- predict(lda.fit, newdata = test)
lda.pred$class
# Cross tabulating the result
table1 <- table(correct = correct_classes, predicted = lda.pred$class)
table1
library(caret); library(lattice); library(mlbench)
confusionMatrix(correct_classes, lda.pred$class)
install.packages("e1071")
# Predicting classes with the test data
lda.pred <- predict(lda.fit, newdata = test)
lda.pred$class
# Cross tabulating the result
table1 <- table(correct = correct_classes, predicted = lda.pred$class)
table1
library(caret); library(lattice); library(mlbench); library(e1071)
confusionMatrix(correct_classes, lda.pred$class)
re_Boston <- Boston
str(re_Boston)
summary(re_Boston)
reboston <- Boston
str(reboston)
summary(reboston)
reboston_scaled <- scale(reboston)
summary(reboston_scaled)
dist_eu <- dist(reboston_scaled)
summary(dist_eu)
# Euclidean distance
dist_eu <- dist(reboston_scaled)
summary(dist_eu)
# Manhattan distance
dist_man <- dist(reboston_scaled, method = "manhattan")
summary(dist_man)
km_eu <- kmean(dist_eu, centers = 4)
km_eu <- kmeans(dist_eu, centers = 4)
km_eu <- kmeans(dist_eu, centers = 4)
pairs(reboston_scaled, col = km_eu$cluster)
km_eu <- kmeans(dist_eu, centers = 4)
library(dygraphs)
pairs(reboston_scaled, col = km_eu$cluster)
km_eu <- kmeans(dist_eu, centers = 4)
library(dygraphs)
pairs(reboston_scaled, col = km_eu$cluster) # 4 centers
km_man <- kmeans(dist_man, centers = 4)
pairs(reboston_scaled, col = km_man$cluster)
set.seed(123)
k_max <- 10
twcss <- sapply(1:k_max, function(k){kmeans(dist_eu, k)$tot.withinss})
plot(1:k_max, twcss, type='b')
library(dygraphs)
km_eu <- kmeans(dist_eu, centers = 2)
pairs(reboston_scaled, col = km_eu$cluster)
km_eu2 <- kmeans(dist_eu, centers = 4)
pairs(reboston_scaled, col = km_eu2$cluster)
km_eu3 <- kmeans(dist_eu, centers = 6)
pairs(reboston_scaled, col = km_eu3$cluster)
library(dygraphs)
km_eu <- kmeans(dist_eu, centers = 2)
pairs(reboston_scaled, col = km_eu$cluster, main = "Pairs with 2 clusters")
km_eu2 <- kmeans(dist_eu, centers = 4)
pairs(reboston_scaled, col = km_eu2$cluster, main = "Pairs with 4 clusters")
km_eu3 <- kmeans(dist_eu, centers = 6)
pairs(reboston_scaled, col = km_eu3$cluster, main = "Pairs with 6 clusters")
# Euclidean distance
dist_eu <- dist(reboston_scaled)
summary(dist_eu)
head(reboston_scaled)
# http://www.sthda.com/english/wiki/determining-the-optimal-number-of-clusters-3-must-known-methods-unsupervised-machine-learning
if(!require(devtools)) install.packages("devtools")
devtools::install_github("kassambara/factoextra")
# http://www.sthda.com/english/wiki/determining-the-optimal-number-of-clusters-3-must-known-methods-unsupervised-machine-learning
pkgs <- c("cluster",  "NbClust")
install.packages(pkgs)
# Euclidean distance
dist_eu <- dist(reboston_scaled)
summary(dist_eu)
set.seed(123)
k_max <- 10
twcss <- sapply(1:k_max, function(k){kmeans(dist_eu, k)$tot.withinss})
plot(1:k_max, twcss, type='b')
set.seed(123)
k_max <- 10
twcss <- sapply(1:k_max, function(k){kmeans(dist_eu, k)$tot.withinss})
plot(1:k_max, twcss, type='b')
library(dygraphs)
set.seed(123)
km_eu <- kmeans(dist_eu, centers = 2)
pairs(reboston_scaled, col = km_eu$cluster, main = "Pairs with 2 clusters")
km_eu2 <- kmeans(dist_eu, centers = 4)
pairs(reboston_scaled, col = km_eu2$cluster, main = "Pairs with 4 clusters")
km_eu3 <- kmeans(dist_eu, centers = 6)
pairs(reboston_scaled, col = km_eu3$cluster, main = "Pairs with 6 clusters")
set.seed(123)
k_max <- 10
twcss <- sapply(1:k_max, function(k){kmeans(dist_eu, k)$tot.withinss})
plot(1:k_max, twcss, type='b')
set.seed(123)
# Compute and plot wss for k = 2 to k = 15
k.max <- 15 # Maximal number of clusters
data <- reboston_scaled
wss <- sapply(1:k.max,
function(k){kmeans(data, k, nstart=10 )$tot.withinss})
plot(1:k.max, wss,
type="b", pch = 19, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares")
abline(v = 3, lty =2)
set.seed(123)
# Compute and plot wss for k = 2 to k = 15
k.max <- 10 # Maximal number of clusters
data <- reboston_scaled
wss <- sapply(1:k.max,
function(k){kmeans(data, k, nstart=10 )$tot.withinss})
plot(1:k.max, wss,
type="b", pch = 19, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares")
abline(v = 3, lty =2)
set.seed(123)
k_max <- 10 # maximum number of clusters
twcss <- sapply(1:k_max, function(k){kmeans(dist_eu, k)$tot.withinss})
plot(1:k_max, twcss, type='b', main = "Suggested amount of clusters")
set.seed(123)
# Compute and plot wss for k = 2 to k = 15
k.max <- 10 # Maximal number of clusters
data <- reboston_scaled
wss <- sapply(1:k.max,
function(k){kmeans(data, k, nstart=10 )$tot.withinss})
plot(1:k.max, wss,
type="b", pch = 10, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares")
abline(v = 3, lty =2)
set.seed(123)
# Compute and plot wss for k = 2 to k = 15
k.max <- 10 # Maximal number of clusters
data <- reboston_scaled
wss <- sapply(1:k.max,
function(k){kmeans(data, k, nstart=10 )$tot.withinss})
plot(1:k.max, wss,
type="b", pch = 1, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares")
abline(v = 3, lty =2)
set.seed(123)
# Compute and plot wss for k = 2 to k = 15
k.max <- 10 # Maximal number of clusters
data <- reboston_scaled
wss <- sapply(1:k.max,
function(k){kmeans(data, k, nstart=10 )$tot.withinss})
plot(1:k.max, wss,
type="b", pch = 1, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares")
abline(v = 4, lty =2)
set.seed(123)
# Compute and plot wss for k = 2 to k = 15
k.max <- 10 # Maximal number of clusters
data <- reboston_scaled
wss <- sapply(1:k.max,
function(k){kmeans(data, k, nstart=10 )$tot.withinss})
plot(1:k.max, wss,
type="b", pch = 1, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares")
abline(v = 4, lty =1)
set.seed(123)
# Compute and plot wss for k = 2 to k = 15
k.max <- 10 # Maximal number of clusters
data <- reboston_scaled
wss <- sapply(1:k.max,
function(k){kmeans(data, k, nstart=10 )$tot.withinss})
plot(1:k.max, wss,
type="b", pch = 1, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares")
abline(v = 4, lty =3)
set.seed(123)
# Compute and plot wss for k = 2 to k = 15
k.max <- 10 # Maximal number of clusters
data <- reboston_scaled
wss <- sapply(1:k.max,
function(k){kmeans(data, k, nstart=10 )$tot.withinss})
plot(1:k.max, wss,
type="b", pch = 1, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares")
abline(v = 4, lty =2)
set.seed(123)
# Compute and plot wss for k = 2 to k = 10
k.max <- 10 # Maximal number of clusters
data <- reboston_scaled
wss <- sapply(1:k.max,
function(k){kmeans(data, k, nstart=10 )$tot.withinss})
plot(1:k.max, wss,
type="b", pch = 1, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares", main = "The amount of clusters")
abline(v = 3, lty =2)
library(dygraphs)
km_eu <- kmeans(dist_eu, centers = 2)
pairs(reboston_scaled, col = km_eu$cluster, main = "Pairs with 2 clusters")
km_eu2 <- kmeans(dist_eu, centers = 4)
pairs(reboston_scaled, col = km_eu2$cluster, main = "Pairs with 4 clusters")
km_eu3 <- kmeans(dist_eu, centers = 6)
pairs(reboston_scaled, col = km_eu3$cluster, main = "Pairs with 6 clusters")
set.seed(123) # keeping the results same
k_max <- 10 # maximum number of clusters
twcss <- sapply(1:k_max, function(k){kmeans(dist_eu, k)$tot.withinss})
plot(1:k_max, twcss, type='b', main = "Suggested number of clusters")
library(factoextra); library(ggplot2)
fviz_nbclust(reboston_scaled, hcut, method = "wss") +
geom_vline(xintercept = 3, linetype = 2)
library(factoextra); require(ggplot2)
fviz_nbclust(reboston_scaled, hcut, method = "wss") +
geom_vline(xintercept = 3, linetype = 2)
set.seed(123)
# Compute and plot wss for k = 2 to k = 10
k.max <- 10 # Maximal number of clusters
data <- reboston_scaled
wss <- sapply(1:k.max,
function(k){kmeans(data, k, nstart=10 )$tot.withinss})
plot(1:k.max, wss,
type="b", pch = 1, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares", main = "The amount of clusters")
abline(v = 3, lty =2)
# Another way, same method
library(factoextra); require(ggplot2)
fviz_nbclust(reboston_scaled, kmeans, method = "wss") +
geom_vline(xintercept = 3, linetype = 2)
set.seed(123)
# Compute and plot wss for k = 2 to k = 10
k.max <- 10 # Maximal number of clusters
data <- reboston_scaled
wss <- sapply(1:k.max,
function(k){kmeans(data, k, nstart=10 )$tot.withinss})
plot1 <- plot(1:k.max, wss,
type="b", pch = 1, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares", main = "The amount of clusters")
abline(v = 3, lty =2)
# Another way, same method
library(factoextra); require(ggplot2)
plot2 <- fviz_nbclust(reboston_scaled, kmeans, method = "wss") +
geom_vline(xintercept = 3, linetype = 2)
library(gridExtra)
grid.arrange(plot1, plot2, ncol=2, nrow =2)
set.seed(123)
# Compute and plot wss for k = 2 to k = 10
k.max <- 10 # Maximal number of clusters
data <- reboston_scaled
wss <- sapply(1:k.max,
function(k){kmeans(data, k, nstart=10 )$tot.withinss})
plot1 <- plot(1:k.max, wss,
type="b", pch = 1, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares", main = "The amount of clusters")
abline(v = 3, lty =2)
# Another way, same method
library(factoextra); require(ggplot2)
plot2 <- fviz_nbclust(reboston_scaled, kmeans, method = "wss") +
geom_vline(xintercept = 3, linetype = 2)
plot1
plot2
set.seed(123)
# Compute and plot wss for k = 2 to k = 10
k.max <- 10 # Maximal number of clusters
data <- reboston_scaled
wss <- sapply(1:k.max,
function(k){kmeans(data, k, nstart=10 )$tot.withinss})
plot1 <- plot(1:k.max, wss,
type="b", pch = 1, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares", main = "The amount of clusters")
abline(v = 3, lty =2)
# Another way, same method
library(factoextra); require(ggplot2)
plot2 <- fviz_nbclust(reboston_scaled, kmeans, method = "wss") +
geom_vline(xintercept = 3, linetype = 2)
library(gridExtra)
grid.arrange(plot1, plot2, nrow =2)
set.seed(123)
# Compute and plot wss for k = 2 to k = 10
k.max <- 10 # Maximal number of clusters
data <- reboston_scaled
wss <- sapply(1:k.max,
function(k){kmeans(data, k, nstart=10 )$tot.withinss})
plot(1:k.max, wss,
type="b", pch = 1, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares", main = "The amount of clusters")
abline(v = 3, lty =2)
# Another way, same method
library(factoextra); require(ggplot2)
fviz_nbclust(reboston_scaled, kmeans, method = "wss") +
geom_vline(xintercept = 3, linetype = 2)
library(dygraphs)
km_eu <- kmeans(dist_eu, centers = 2)
pairs(reboston_scaled, col = km_eu$cluster, main = "Pairs with 2 clusters")
km_eu2 <- kmeans(dist_eu, centers = 4)
pairs(reboston_scaled, col = km_eu2$cluster, main = "Pairs with 4 clusters")
set.seed(123)
km_eu3 <- kmeans(dist_eu, centers = 3)
pairs(reboston_scaled, col = km_eu3$cluster, main = "Pairs with 3 clusters")
km_eu4 <- kmeans(dist_eu, centers = 5)
pairs(reboston_scaled, col = km_eu4$cluster, main = "Pairs with 5 clusters")
set.seed(123)
km_eu3 <- kmeans(dist_eu, centers = 3)
pairs(reboston_scaled, col = km_eu3$cluster, main = "Pairs with 3 clusters")
km_eu4 <- kmeans(dist_eu, centers = 5)
pairs(reboston_scaled, col = km_eu4$cluster, main = "Pairs with 5 clusters")
library(NbClust)
nb <- NbClust(reboston_scaled, distance = "euclidean", min.nc = 2,
max.nc = 10, method = "complete", index ="all")
nb
fviz_nbclust(nb) + theme_minimal()
set.seed(123) # keeping the results same
k_max <- 10 # maximum number of clusters
twcss <- sapply(1:k_max, function(k){kmeans(dist_eu, k)$tot.withinss})
plot(1:k_max, twcss, type='b', main = "Number of clusters")
set.seed(123) # keeping the results same
k_max <- 10 # maximum number of clusters
twcss <- sapply(1:k_max, function(k){kmeans(dist_eu, k)$tot.withinss})
plot(1:k_max, twcss, type='b', main = "Number of proposed clusters")
set.seed(123)
# Compute and plot wss for k = 2 to k = 10
k.max <- 10 # Maximal number of clusters
data <- reboston_scaled
wss <- sapply(1:k.max,
function(k){kmeans(data, k, nstart=10 )$tot.withinss})
plot(1:k.max, wss,
type="b", pch = 1, frame = FALSE,
xlab="Number of clusters K",
ylab="Total within-clusters sum of squares", main = "The amount of clusters")
abline(v = 2, lty =2)
# Another way, same method
library(factoextra); require(ggplot2)
fviz_nbclust(reboston_scaled, kmeans, method = "wss") +
geom_vline(xintercept = 5, linetype = 2)
set.seed(123)
km_eu3 <- kmeans(dist_eu, centers = 3)
pairs(reboston_scaled, col = km_eu3$cluster, main = "Pairs with 3 clusters")
library(dygraphs)
km_eu <- kmeans(dist_eu, centers = 2)
pairs(reboston_scaled, col = km_eu$cluster, main = "Pairs with 2 clusters")
km_eu
km_eu2 <- kmeans(dist_eu, centers = 4)
pairs(reboston_scaled, col = km_eu2$cluster, main = "Pairs with 4 clusters")
km_eu2
library(dygraphs)
km_eu <- kmeans(dist_eu, centers = 2)
pairs(reboston_scaled, col = km_eu$cluster, main = "Pairs with 2 clusters")
km_eu2 <- kmeans(dist_eu, centers = 4)
pairs(reboston_scaled, col = km_eu2$cluster, main = "Pairs with 4 clusters")
# Lets plot the pairs with two centers again
km_eu
# Lets plot the pairs with two centers again
library(dygraphs)
pairs(reboston_scaled, col = km_eu$cluster, main = "Pairs with 2 clusters")
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", stringsAsFactors = F)
gii <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv", stringsAsFactors = F, na.strings = "..")
str(hd)
dim(hd)
summary(hd)
str(gii)
summary(gii)
table(is.na(hd))
table(is.na(gii))
colnames(hd)
HDI_rank <- hd$HDI.Rank # The rank of a country in the Human development index
country <- hd$Country
HDI_index <- hd$Human.Development.Index..HDI. # Human development index per country
Elife <- hd$Life.Expectancy.at.Birth # Expected life years at birth per country
Eedu <- hd$Expected.Years.of.Education # Expected years of schooling per country
Medu <- hd$Mean.Years.of.Education # Mean years of schooling per country
GNIpc <- hd$Gross.National.Income..GNI..per.Capita # Gross national income per capita per country in PPP (https://en.wikipedia.org/wiki/Purchasing_power_parity)
GH_rank <- hd$GNI.per.Capita.Rank.Minus.HDI.Rank # Gross national income per capita rank minus HDI rank
colnames(hd)
library(dplyr)
rename(hd, HDI.Rank = HDI_rank)
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", stringsAsFactors = F)
gii <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv", stringsAsFactors = F, na.strings = "..")
str(hd) # 195 observations and 8 variables: 2 integers, 2 character and 4 numeric (continous) variables
str(gii) # 195 observations and 10 variables: 2 integers, 1 character and 7 numeric (continuous) variables
rename(hd, HDI.Rank = HDI_rank)
rename(hd, HDI_rank = HDI.Rank)
colnames(hd)
rename(hd, HDI_rank = HDI.Rank, country = Country)
rename(hd, HDI_rank = HDI.Rank,
country = Country,
HDI_index = Human.Development.Index..HDI.,
Elife = Life.Expectancy.at.Birth,
Eedu = Expected.Years.of.Education,
Medu = Expected.Years.of.Education,
GNIpc = Gross.National.Income..GNI..per.Capita,
GH_rank = GNI.per.Capita.Rank.Minus.HDI.Rank)
colnames(hd)
hd <- rename(hd, HDI_rank = HDI.Rank,
country = Country,
HDI_index = Human.Development.Index..HDI.,
Elife = Life.Expectancy.at.Birth,
Eedu = Expected.Years.of.Education,
Medu = Expected.Years.of.Education,
GNIpc = Gross.National.Income..GNI..per.Capita,
GH_rank = GNI.per.Capita.Rank.Minus.HDI.Rank)
colnames(hd)
hd <- rename(hd, HDI_rank = HDI.Rank,
country = Country,
HDI_index = Human.Development.Index..HDI.,
Elife = Life.Expectancy.at.Birth,
Eedu = Expected.Years.of.Education,
Medu = Mean.Years.of.Education,
GNIpc = Gross.National.Income..GNI..per.Capita,
GH_rank = GNI.per.Capita.Rank.Minus.HDI.Rank)
Medu = Mean.Years.of.Education
hd <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/human_development.csv", stringsAsFactors = F)
gii <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/gender_inequality.csv", stringsAsFactors = F, na.strings = "..")
hd <- rename(hd, HDI_rank = HDI.Rank,
country = Country,
HDI_index = Human.Development.Index..HDI.,
Elife = Life.Expectancy.at.Birth,
Eedu = Expected.Years.of.Education,
Medu = Mean.Years.of.Education,
GNIpc = Gross.National.Income..GNI..per.Capita,
GH_rank = GNI.per.Capita.Rank.Minus.HDI.Rank)
colnames(hd)
colnames(gii) # Printing just the column names
gii <- rename(gee,
GII_rank = GII.Rank,
country = Country,
GII_index = Gender.Inequality.Index..GII.,
mort_ratio = Maternal.Mortality.Ratio,
ad_birth = Adolescent.Birth.Rate,
seats = Percent.Representation.in.Parliament,
SFedu = Population.with.Secondary.Education..Female.,
SMedu = Population.with.Secondary.Education..Male.,
Flabour = Labour.Force.Participation.Rate..Female.,
Mlabour = Labour.Force.Participation.Rate..Male.)
gii <- rename(gii,
GII_rank = GII.Rank,
country = Country,
GII_index = Gender.Inequality.Index..GII.,
mort_ratio = Maternal.Mortality.Ratio,
ad_birth = Adolescent.Birth.Rate,
seats = Percent.Representation.in.Parliament,
SFedu = Population.with.Secondary.Education..Female.,
SMedu = Population.with.Secondary.Education..Male.,
Flabour = Labour.Force.Participation.Rate..Female.,
Mlabour = Labour.Force.Participation.Rate..Male.)
colnames(gii) # Verifying the column names
gii <- mutate(gii, SFM_edu = SFedu / SMedu, FMlabour = Flabour / Mlabour)
colnames(gii)
join_by <- c("country")
human <- inner_join(hd, gii, by = c(join_by), suffix = c(".hd", ".gii"))
colnames(human)
glimpse(human)
setwd("C:/Users/heidi/Documents/YLIOPISTO/TILASTOTIEDE/INTRODUCTION TO OPEN DATA SCIENCE/IODS-project/data")
getwd()
